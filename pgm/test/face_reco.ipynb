{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- tenir compte des dernières frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import os\n",
    "import moviepy.editor as mpe\n",
    "import gc\n",
    "import numpy as np\n",
    "import sys\n",
    "import uuid\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/franzele/Desktop/univ_lille/m1s2/pji/pgm/test'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def retrieve_audio(video):\n",
    "#     video_clip = mpe.VideoFileClip(video)\n",
    "\n",
    "#     # Extract the audio from the video clip\n",
    "#     audio_clip = video_clip.audio\n",
    "#     video_clip.close()\n",
    "\n",
    "#     return audio_clip\n",
    "# def combine_audio(video, audio, outname, fps):\n",
    "#     final_clip = video.set_audio(audio)\n",
    "#     # os.remove(outname)\n",
    "#     print(type(final_clip))\n",
    "#     final_clip.write_videofile(f\"f{outname}\", fps=fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models(model_dir=\"models\"):\n",
    "    model_list = []\n",
    "    for model_name in os.listdir(model_dir):\n",
    "        model_list.append(YOLO(os.path.join(model_dir, model_name)))\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def variable_blur(data, kernel_size):\n",
    "#   \"\"\" Blur with a variable window size\n",
    "#   Parameters:\n",
    "#   - data: 2D ndarray of floats or integers\n",
    "#   - kernel_size: 2D ndarray of integers, same shape as data\n",
    "#   Returns:\n",
    "#   2D ndarray\n",
    "#   \"\"\"\n",
    "#   data_blurred = np.empty(data.shape)\n",
    "#   print(data_blurred)\n",
    "#   Ni, Nj, Nk = data.shape\n",
    "#   for i in range(Ni):\n",
    "#     for j in range(Nj):\n",
    "#       for k in range(Nk):\n",
    "\n",
    "#         res = 0.0\n",
    "#         weight = 0\n",
    "#         sigma =  kernel_size[i, j, k]\n",
    "#         for ii in range(i - sigma, i+sigma+1):\n",
    "#           for jj in range(j - sigma, j+sigma+1):\n",
    "#             if ii<0 or ii>=Ni or jj < 0 or jj >= Nj:\n",
    "#               continue\n",
    "#             res += data[ii, jj]\n",
    "#             weight += 1\n",
    "#         print(i, j, k)\n",
    "#         data_blurred[i, j, k] = res/weight\n",
    "#   return data_blurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur_box(frame, box, min_conf=0.3):\n",
    "    if math.ceil((box.conf[0]*100))/100 > min_conf:\n",
    "        x1, y1, x2, y2 = box.xyxy[0]\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "        h, w = y2-y1, x2-x1\n",
    "\n",
    "        ROI = frame[y1:y1+h, x1:x1+w]\n",
    "        blur = cv2.GaussianBlur(ROI, (51,51), 0) \n",
    "        frame[y1:y1+h, x1:x1+w] = blur\n",
    "        # frame[y1:y1+h, x1:x1+w] = np.zeros((h, w, 3))\n",
    "    return frame\n",
    "\n",
    "def read_video_file(video_path):\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    return vidcap, \\\n",
    "            int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT)), \\\n",
    "            vidcap.get(cv2.CAP_PROP_FPS), \\\n",
    "            (int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "\n",
    "def create_video_file(output_path, fps, frame_size):\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter(filename=output_path, \n",
    "                        fourcc=fourcc, \n",
    "                        fps=fps, \n",
    "                        frameSize=frame_size)\n",
    "    return video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmp_video(orig_video, output_video, frame_rate):\n",
    "    vidcap, frame_number, fps, frame_size = read_video_file(orig_video)\n",
    "    video = create_video_file(output_video, fps, frame_size)\n",
    "    success, img = vidcap.read()\n",
    "    i=0\n",
    "    while success:\n",
    "        if i%frame_rate == 0:\n",
    "            video.write(img)\n",
    "        i+=1\n",
    "        success, img = vidcap.read()\n",
    "    # on prends la dernière frame\n",
    "    if (i-1)%frame_rate != 0:\n",
    "        video.write(img)\n",
    "    del i\n",
    "    del img\n",
    "    del success\n",
    "    vidcap.release\n",
    "    video.release()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform1(model, video_path, output_path, frame_verif_rate=5, verbose=False):\n",
    "    if verbose: print(\"Création vidéo temporaire\")\n",
    "    tmp_video_name = f\"{uuid.uuid4().hex}.mp4\"\n",
    "    tmp_video(video_path, tmp_video_name, frame_verif_rate)\n",
    "    gc.collect()\n",
    "\n",
    "    if verbose: print(\"Floutage\")\n",
    "    vidcap_s, frame_number_s, _, _ = read_video_file(tmp_video_name)\n",
    "    vidcap_o, _, fps_o, frame_size_o = read_video_file(video_path)\n",
    "    video = create_video_file(output_path, fps_o, frame_size_o)\n",
    "    success_s, img_s = vidcap_s.read()\n",
    "    assert success_s, \"Error while loading the temp video\"\n",
    "\n",
    "    for i in tqdm(range(frame_number_s)):\n",
    "        results_s = model(img_s, verbose=False, stream=True)\n",
    "        to_blur = len(next(results_s).boxes.conf) > 0\n",
    "        del results_s ; gc.collect()\n",
    "        # première frame\n",
    "        if i == 0:\n",
    "            for j in range(math.ceil(frame_verif_rate/2)):\n",
    "                success_o, img_o = vidcap_o.read()\n",
    "                if to_blur:\n",
    "                    boxes = next(model(img_o, verbose=False, stream=True)).boxes\n",
    "                    for box in boxes:\n",
    "                        img_o = blur_box(img_o, box)\n",
    "                video.write(img_o)\n",
    "        # autre frame\n",
    "        else:\n",
    "            for j in range(frame_verif_rate):\n",
    "                success_o, img_o = vidcap_o.read()\n",
    "                if to_blur:\n",
    "                    boxes = next(model(img_o, verbose=False, stream=True)).boxes\n",
    "                    for box in boxes:\n",
    "                        img_o = blur_box(img_o, box)\n",
    "                video.write(img_o)\n",
    "            # dernières frames\n",
    "            if i+1 == frame_number_s:\n",
    "                success_o, img_o = vidcap_o.read()\n",
    "                while success_o:\n",
    "                    video.write(img_o)\n",
    "                    if to_blur:\n",
    "                        boxes = next(model(img_o, verbose=False, stream=True)).boxes\n",
    "                        for box in boxes:\n",
    "                            img_o = blur_box(img_o, box)\n",
    "                    success_o, img_o = vidcap_o.read()\n",
    "\n",
    "        success_s, img_s= vidcap_s.read()\n",
    "\n",
    "    vidcap_s.release()\n",
    "    vidcap_o.release()\n",
    "    video.release()\n",
    "    if verbose: print(\"Suppression vidéo temporaire\")\n",
    "    os.remove(tmp_video_name)\n",
    "\n",
    "    if verbose: print(\"========= FIN =========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform2(model_list, video_path, output_path):\n",
    "    vidcap, frame_number, fps, frame_size = read_video_file(video_path)\n",
    "    video = create_video_file(output_path, fps, frame_size)\n",
    "\n",
    "    results = [model(video_path, verbose=True) for model in model_list]\n",
    "    mean_conf = torch.tensor([[i.conf for x in r for i in x.boxes] for r in results]).mean(1).item()\n",
    "    conf_tol = mean_conf * 0.75\n",
    "    interesting_frame = torch.tensor([[(x.boxes.conf > conf_tol).any().item() for x in r] for r in results]).any(0).tolist()\n",
    "    \n",
    "    success, img = vidcap.read()\n",
    "    if success:\n",
    "        for i in tqdm(range(frame_number)):\n",
    "            if interesting_frame[i]:\n",
    "                for result_id in range(len(model_list)):\n",
    "                    frame_result = results[result_id][i]\n",
    "                    for r in frame_result:\n",
    "                        boxes = r.boxes\n",
    "                        for box in boxes:\n",
    "                            img = blur_box(img, box, conf_tol)\n",
    "\n",
    "            video.write(img)\n",
    "            success, img = vidcap.read()\n",
    "    vidcap.release()\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_list = get_models()\n",
    "model_list = [\n",
    "    YOLO(\"models/yolov8n-face.pt\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Création vidéo temporaire\n",
      "Floutage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:19<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suppression vidéo temporaire\n",
      "========= FIN =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform1(model_list[0], \"pietons2.mp4\", \"video.mp4\", frame_verif_rate=12, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform2(model_list, \"action_bronson.mp4\", \"video2.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
