{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv_bridge import CvBridge\n",
    "from rosbags.rosbag2 import Reader, Writer\n",
    "from rosbags.typesys import Stores, get_typestore\n",
    "import rosbags.image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import rospy.rostime\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "import shutil\n",
    "import math\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_list(box_list: list, frame_rate:int=1, box_difference:int=5):\n",
    "    \"\"\"\n",
    "    Modifies a list of lists (`box_list`) by filling in gaps and ensuring continuity between frames\n",
    "    based on spatial proximity of bounding boxes.\n",
    "\n",
    "    This function iterates through each list of boxes (representing frames) and checks for continuity \n",
    "    of each box between consecutive frames. If a box in a previous frame does not have a close match \n",
    "    in the current frame but has one in subsequent frames (within a specified `frame_rate`), a mean \n",
    "    box is created to bridge the gap.\n",
    "\n",
    "    It will also add a box at before the first occurance of a box, for a more smooth blurring\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    box_list : list of list of list of float\n",
    "        A list where each element is a list representing a frame of bounding boxes, and each bounding \n",
    "        box is a list of floats representing its coordinates.\n",
    "    frame_rate : int, optional\n",
    "        The number of frames to look ahead for matching a box from the previous frame, default is 1.\n",
    "    box_difference : int, optional\n",
    "        The allowed difference between the coordinates of boxes for them to be considered close, \n",
    "        default is 5.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of list of list of float\n",
    "        The modified `box_list` with added boxes to ensure continuity between frames.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> boxes = [\n",
    "            [\n",
    "                [10, 10, 20, 20],\n",
    "                [20, 20, 40, 40]\n",
    "            ],\n",
    "            [\n",
    "                [100, 100, 150, 150]\n",
    "            ],\n",
    "            [\n",
    "                [20, 20, 40, 40]\n",
    "            ],\n",
    "            [\n",
    "                [15, 15, 25, 25]\n",
    "            ]\n",
    "        ]\n",
    "    >>> fill_list(boxes, frame_rate=3)\n",
    "    [\n",
    "        [\n",
    "            [10, 10, 20, 20], \n",
    "            [20, 20, 40, 40], \n",
    "            [100, 100, 150, 150]        # was added \n",
    "        ],\n",
    "        [\n",
    "            [100, 100, 150, 150], \n",
    "            [12.5, 12.5, 22.5, 22.5],   # was added\n",
    "            [20.0, 20.0, 40.0, 40.0]    # was added\n",
    "        ],\n",
    "        [\n",
    "            [20, 20, 40, 40], \n",
    "            [13.75, 13.75, 23.75, 23.75]    # was added\n",
    "        ],\n",
    "        [\n",
    "            [15, 15, 25, 25]\n",
    "        ]\n",
    "    ]\n",
    "    \"\"\"\n",
    "    for i in range(1, len(box_list)-1):\n",
    "        # on regarde les boxes de la frame précédente\n",
    "        for last_boxes in box_list[i-1]:\n",
    "            correspondance_now = False\n",
    "            for present_boxe in box_list[i]:\n",
    "                # on trouve une frame ressemblante dans la frame actuelle\n",
    "                if np.isclose(last_boxes, present_boxe, atol=box_difference).all():\n",
    "                    correspondance_now = True\n",
    "            # si on trouve, alors on s'arrête là (pas besoin de créer de boxe)\n",
    "            if correspondance_now:\n",
    "                continue\n",
    "            \n",
    "            # on regarde si les frames d'après ressemble à une box de la frame précédente\n",
    "            correspondance_after = False\n",
    "            for j in range(frame_rate):\n",
    "                if len(box_list) > i+j+1:\n",
    "                    for next_boxe in box_list[i+j+1]:\n",
    "                        # on trouve une frame ressemblante\n",
    "                        if np.isclose(last_boxes, next_boxe, atol=box_difference).all():\n",
    "                            correspondance_after = True\n",
    "                            break\n",
    "                    if correspondance_after:\n",
    "                        break\n",
    "            \n",
    "            # si on trouve une frame ressemblante, alors on créer une approximation entre la\n",
    "            # boxe de la frame précédente et suivante\n",
    "            if correspondance_after:\n",
    "                box_list[i].append(np.mean([last_boxes, next_boxe], axis=0).tolist())\n",
    "\n",
    "        # on rajoute des boxes aux frames précédentes\n",
    "        for present_boxe in box_list[i]:\n",
    "            correspondance = False\n",
    "            for last_boxe in box_list[i-1]:\n",
    "                if np.isclose(last_boxe, present_boxe, atol=box_difference).all():\n",
    "                    correspondance = True\n",
    "            if not correspondance:\n",
    "                for j in range(frame_rate):\n",
    "                    if i-j-1 >= 0:\n",
    "                        box_list[i-j-1].append(present_boxe)\n",
    "\n",
    "    return box_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur_box1(frame: np.ndarray, \n",
    "             box: list, \n",
    "             black_box: bool=False):\n",
    "    \"\"\"\n",
    "    Apply a blur or black box to a specified region of an image if the confidence level is above a threshold.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    frame : numpy.ndarray\n",
    "        The image on which the blur or black box is to be applied. It should be a 3D array representing an RGB image.\n",
    "    box : object\n",
    "        An object containing the bounding box coordinates and confidence score. It should have attributes `conf` and `xyxy`:\n",
    "        - `box.conf` : list or numpy.ndarray\n",
    "            The confidence score(s) of the bounding box, with values between 0 and 1.\n",
    "        - `box.xyxy` : list or numpy.ndarray\n",
    "            The coordinates of the bounding box in the format [x1, y1, x2, y2].\n",
    "    black_box : bool, optional\n",
    "        If True, the specified region is filled with a black box instead of being blurred. Default is False.\n",
    "    min_conf : float, optional\n",
    "        The minimum confidence threshold to apply the blur or black box. Default is 0.3. Must in [0, 1].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        The modified image with the blur or black box applied to the specified region.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - The input `frame` must be a 3D NumPy array representing an image with shape (height, width, channels).\n",
    "    - The bounding box coordinates and confidence score must be provided in the `box` object (already implemented in the Yolov8 results).\n",
    "    - If `black_box` is set to True, the region within the bounding box will be replaced with black pixels (faster than blurring).\n",
    "    - The Gaussian blur applied uses a kernel size of (51, 51) with a standard deviation of 0.\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = box\n",
    "    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "    h, w = y2-y1, x2-x1\n",
    "\n",
    "    if black_box:\n",
    "        blur = blur = np.ones((h, w, 3)) * np.array([255, 0, 0])\n",
    "    else:\n",
    "        ROI = frame[y1:y1+h, x1:x1+w]\n",
    "        blur = cv2.GaussianBlur(ROI, (51,51), 0) \n",
    "    frame[y1:y1+h, x1:x1+w] = blur\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bridge = CvBridge()\n",
    "model = YOLO(\"models/yolov8n-face.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_BAGFILE = '../../2022-11-17_pietons/Acquis2805_grise/'\n",
    "OUTPUT_BAGFILE = 'output_ros2'\n",
    "\n",
    "frame_rate = 5\n",
    "min_conf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# cŕeation sortie\n",
    "if not os.path.exists(OUTPUT_BAGFILE): os.mkdir(OUTPUT_BAGFILE)\n",
    "\n",
    "db3_file_list = [file for file in os.listdir(OUTPUT_BAGFILE) if \".db\" in file]\n",
    "if len(db3_file_list) == 0:\n",
    "    db3_file_name = [file for file in os.listdir(INPUT_BAGFILE) if len(file)> 1 and\".db3\" == file[-4:]][0]\n",
    "    shutil.copyfile(os.path.join(INPUT_BAGFILE, db3_file_name), os.path.join(OUTPUT_BAGFILE, db3_file_name))\n",
    "else:\n",
    "    db3_file_name = db3_file_list[0]\n",
    "\n",
    "yaml_file_list = [file for file in os.listdir(OUTPUT_BAGFILE) if \".yaml\" in file]\n",
    "if len(yaml_file_list) == 0:\n",
    "    yaml_file_name = [file for file in os.listdir(INPUT_BAGFILE) if len(file)> 1 and\".yaml\" == file[-5:]][0]\n",
    "    shutil.copyfile(os.path.join(INPUT_BAGFILE, yaml_file_name), os.path.join(OUTPUT_BAGFILE, yaml_file_name))\n",
    "\n",
    "db3_path = os.path.join(OUTPUT_BAGFILE, db3_file_name)\n",
    "\n",
    "db3_connection = sqlite3.connect(db3_path)\n",
    "cursor = db3_connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "topic_id = cursor.execute(r\"SELECT id FROM topics WHERE name like '%image_raw%';\").fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# vérification chaque x frames\n",
    "typestore = get_typestore(Stores.LATEST)\n",
    "\n",
    "interesting_frames = []\n",
    "# Create reader instance and open for reading.\n",
    "with Reader('../../2022-11-17_pietons/Acquis2805_grise/') as reader:\n",
    "    last_i = 0\n",
    "    # Iterate over messages.\n",
    "    for i, (connection, timestamp, rawdata) in enumerate(reader.messages()):\n",
    "        if connection.topic == '/d435i/color/image_raw':\n",
    "            last_rawdata = rawdata\n",
    "            last_i = i\n",
    "            if i%frame_rate == 0:\n",
    "                \n",
    "                msg = typestore.deserialize_cdr(rawdata, connection.msgtype)\n",
    "                img = bridge.imgmsg_to_cv2(msg, desired_encoding=\"bgr8\")\n",
    "                \n",
    "                boxes = next(model(img, stream=True, verbose=False)).boxes\n",
    "                if len(boxes) > 0:\n",
    "                    interesting_frames.append(True)\n",
    "                else:\n",
    "                    interesting_frames.append(False)\n",
    "if last_i%frame_rate != 0:\n",
    "    msg = typestore.deserialize_cdr(last_rawdata, connection.msgtype)\n",
    "    img = bridge.imgmsg_to_cv2(msg, desired_encoding=\"bgr8\")\n",
    "    \n",
    "    boxes = next(model(img, stream=True, verbose=False)).boxes\n",
    "    if len(boxes) > 0:\n",
    "        interesting_frames.append(True)\n",
    "    else:\n",
    "        interesting_frames.append(False)\n",
    "# pd.DataFrame(interesting_frames).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"rm -Rf jsp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"boxes_list\") as file:\n",
    "    boxes_list = eval(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "92566it [02:41, 571.69it/s] \n",
      "218it [00:00, 8386.07it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Time' object has no attribute 'sec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m image_message \u001b[38;5;241m=\u001b[39m bridge\u001b[38;5;241m.\u001b[39mcv2_to_imgmsg(img, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     81\u001b[0m image_message \u001b[38;5;241m=\u001b[39m Image(\n\u001b[1;32m     82\u001b[0m     image_message\u001b[38;5;241m.\u001b[39mheader,\n\u001b[1;32m     83\u001b[0m     image_message\u001b[38;5;241m.\u001b[39mheight,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m     image_message\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m     89\u001b[0m )\n\u001b[0;32m---> 90\u001b[0m new_msg \u001b[38;5;241m=\u001b[39m \u001b[43mtypestore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserialize_cdr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_message\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msensor_msgs/msg/Image\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m writer\u001b[38;5;241m.\u001b[39mwrite(writer_connection, timestamp, new_msg)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# sql = f\"UPDATE messages SET data=? WHERE timestamp={timestamp} AND topic_id={topic_id}\"\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# cursor.execute(sql, (image_message, ))\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# db3_connection.commit()\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/rosbags/typesys/store.py:166\u001b[0m, in \u001b[0;36mTypestore.serialize_cdr\u001b[0;34m(self, message, typename, little_endian)\u001b[0m\n\u001b[1;32m    162\u001b[0m pack_into(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBB\u001b[39m\u001b[38;5;124m'\u001b[39m, rawdata, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, little_endian)\n\u001b[1;32m    164\u001b[0m func \u001b[38;5;241m=\u001b[39m msgdef\u001b[38;5;241m.\u001b[39mserialize_cdr_le \u001b[38;5;28;01mif\u001b[39;00m little_endian \u001b[38;5;28;01melse\u001b[39;00m msgdef\u001b[38;5;241m.\u001b[39mserialize_cdr_be\n\u001b[0;32m--> 166\u001b[0m pos \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrawdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m pos \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m==\u001b[39m size\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rawdata\u001b[38;5;241m.\u001b[39mtoreadonly()\n",
      "File \u001b[0;32m<string>:20\u001b[0m, in \u001b[0;36mserialize_cdr\u001b[0;34m(rawdata, pos, message, typestore)\u001b[0m\n",
      "File \u001b[0;32m<string>:20\u001b[0m, in \u001b[0;36mserialize_cdr\u001b[0;34m(rawdata, pos, message, typestore)\u001b[0m\n",
      "File \u001b[0;32m<string>:18\u001b[0m, in \u001b[0;36mserialize_cdr\u001b[0;34m(rawdata, pos, message, typestore)\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Time' object has no attribute 'sec'"
     ]
    }
   ],
   "source": [
    "os.system(\"rm -Rf jsp\")\n",
    "# création boxes pour frames intérressantes et voisines\n",
    "typestore = get_typestore(Stores.LATEST)\n",
    "Image = typestore.types['sensor_msgs/msg/Image']\n",
    "\n",
    "\n",
    "with Reader(INPUT_BAGFILE) as reader, Writer(OUTPUT_BAGFILE) as writer:\n",
    "    last_imgs = []\n",
    "    boxes_list = []\n",
    "    begin = True\n",
    "    save_imgs = False\n",
    "    print(reader.message_count)\n",
    "    for connection, timestamp, rawdata in tqdm(reader.messages()):\n",
    "        if connection.topic == '/d435i/color/image_raw':\n",
    "            topic_msg_type = connection.msgtype\n",
    "            msg = typestore.deserialize_cdr(rawdata, connection.msgtype)\n",
    "            topic_msg = msg\n",
    "            img = bridge.imgmsg_to_cv2(msg, desired_encoding=\"bgr8\").copy()\n",
    "            last_imgs.append(img)\n",
    "\n",
    "            if begin and len(last_imgs) == math.ceil(frame_rate/2):\n",
    "                begin = False\n",
    "                save_imgs = True\n",
    "                idx_img = 0\n",
    "            elif len(last_imgs) == frame_rate:\n",
    "                save_imgs = True\n",
    "                idx_img = math.ceil(frame_rate/2)-1\n",
    "\n",
    "            if save_imgs:\n",
    "                save_imgs = False\n",
    "                boxes = next(model(last_imgs[idx_img], stream=True, verbose=False)).boxes\n",
    "                to_blur = len(boxes) > 0\n",
    "                for img in last_imgs:\n",
    "                    boxes_list.append([])\n",
    "                    if to_blur:\n",
    "                        boxes = next(model(img, stream=True, verbose=False)).boxes\n",
    "                        if len(boxes.conf) > 0:\n",
    "                            if isinstance(min_conf, type(None)):\n",
    "                                min_conf = boxes.conf.mean() * 0.6\n",
    "                            else:\n",
    "                                min_conf = (min_conf + boxes.conf.mean())/2 *0.6\n",
    "                        for box in boxes:\n",
    "                            if box.conf[0] > min_conf:\n",
    "                                boxes_list[-1].append(box.xyxy[0].tolist())\n",
    "                last_imgs = []\n",
    "    # dernières frames\n",
    "    boxes = next(model(last_imgs[-1], stream=True, verbose=False)).boxes\n",
    "    to_blur = len(boxes) > 0\n",
    "    for img in last_imgs:\n",
    "        boxes_list.append([])\n",
    "        if to_blur:\n",
    "            boxes = next(model(img, stream=True, verbose=False)).boxes\n",
    "            \n",
    "            for box in boxes:\n",
    "                boxes_list[-1].append(box.xyxy[0].tolist())\n",
    "\n",
    "    boxes_list = fill_list(boxes_list, frame_rate*2, math.ceil(math.sqrt(max(msg.width, msg.height)))*2.5)\n",
    "\n",
    "    # fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    # video = cv2.VideoWriter(filename=\"supp.mp4\", \n",
    "    #                     fourcc=fourcc, \n",
    "    #                     fps=15, \n",
    "    #                     frameSize=(topic_msg.width, topic_msg.height))\n",
    "\n",
    "    idx_boxes = 0\n",
    "    writer_connection = writer.add_connection(\"/d435i/color/image_raw\", 'sensor_msgs/msg/Image', typestore=typestore)\n",
    "    for connection, timestamp, rawdata in tqdm(reader.messages()):\n",
    "        if connection.topic == \"/d435i/color/image_raw\":\n",
    "            # msg = typestore.deserialize_cdr(rawdata, connection.msgtype)\n",
    "            # img = bridge.imgmsg_to_cv2(msg, desired_encoding=\"bgr8\").copy()\n",
    "            # for box in boxes_list[idx_boxes]:\n",
    "            #     img = blur_box1(img, box)\n",
    "            # video.write(img)\n",
    "            if len(boxes_list[idx_boxes]) > 0:\n",
    "                msg = typestore.deserialize_cdr(rawdata, connection.msgtype)\n",
    "                img = bridge.imgmsg_to_cv2(msg, desired_encoding=\"rgb8\").copy()\n",
    "                for box in boxes_list[idx_boxes]:\n",
    "                    img = blur_box1(img, box)\n",
    "\n",
    "                image_message = bridge.cv2_to_imgmsg(img, encoding=\"rgb8\")\n",
    "                image_message = Image(\n",
    "                    image_message.header,\n",
    "                    image_message.height,\n",
    "                    image_message.width,\n",
    "                    image_message.encoding,\n",
    "                    image_message.is_bigendian,\n",
    "                    image_message.step,\n",
    "                    image_message.data\n",
    "                )\n",
    "                new_msg = typestore.serialize_cdr(image_message, 'sensor_msgs/msg/Image')\n",
    "                writer.write(writer_connection, timestamp, new_msg)\n",
    "                # sql = f\"UPDATE messages SET data=? WHERE timestamp={timestamp} AND topic_id={topic_id}\"\n",
    "                # cursor.execute(sql, (image_message, ))\n",
    "                # db3_connection.commit()\n",
    "\n",
    "            idx_boxes += 1\n",
    "\n",
    "# video.release()\n",
    "os.system(\"rm -Rf jsp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 720)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg.width, msg.height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"boxes_list\", \"w\") as file:\n",
    "    file.write(str(boxes_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db3_connection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdb3_connection\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'db3_connection' is not defined"
     ]
    }
   ],
   "source": [
    "db3_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6971"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(boxes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sensor_msgs.msg._Image.Image"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(image_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "384it [00:00, 1530.65it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m connection, timestamp, rawdata \u001b[38;5;129;01min\u001b[39;00m tqdm(reader\u001b[38;5;241m.\u001b[39mmessages()):\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m connection\u001b[38;5;241m.\u001b[39mtopic \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/d435i/color/image_raw\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 12\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[43mtypestore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_cdr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrawdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmsgtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m             video\u001b[38;5;241m.\u001b[39mwrite(bridge\u001b[38;5;241m.\u001b[39mimgmsg_to_cv2(msg, desired_encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbgr8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     14\u001b[0m video\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/rosbags/typesys/store.py:136\u001b[0m, in \u001b[0;36mTypestore.deserialize_cdr\u001b[0;34m(self, rawdata, typename)\u001b[0m\n\u001b[1;32m    134\u001b[0m msgdef \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_msgdef(typename)\n\u001b[1;32m    135\u001b[0m func \u001b[38;5;241m=\u001b[39m msgdef\u001b[38;5;241m.\u001b[39mdeserialize_cdr_le \u001b[38;5;28;01mif\u001b[39;00m little_endian \u001b[38;5;28;01melse\u001b[39;00m msgdef\u001b[38;5;241m.\u001b[39mdeserialize_cdr_be\n\u001b[0;32m--> 136\u001b[0m message, pos \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrawdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsgdef\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m pos \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(rawdata)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m message\n",
      "File \u001b[0;32m<string>:20\u001b[0m, in \u001b[0;36mdeserialize_cdr\u001b[0;34m(rawdata, pos, cls, typestore)\u001b[0m\n",
      "File \u001b[0;32m<string>:20\u001b[0m, in \u001b[0;36mdeserialize_cdr\u001b[0;34m(rawdata, pos, cls, typestore)\u001b[0m\n",
      "File \u001b[0;32m<string>:19\u001b[0m, in \u001b[0;36mdeserialize_cdr\u001b[0;34m(rawdata, pos, cls, typestore)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video = cv2.VideoWriter(filename=\"supp.mp4\", \n",
    "                    fourcc=fourcc, \n",
    "                    fps=15, \n",
    "                    frameSize=(msg.width, msg.height))\n",
    "\n",
    "with Reader(OUTPUT_BAGFILE) as reader:\n",
    "    print(reader.message_count)\n",
    "    # Iterate over messages.\n",
    "    for connection, timestamp, rawdata in tqdm(reader.messages()):\n",
    "        if connection.topic == '/d435i/color/image_raw':\n",
    "            msg = typestore.deserialize_cdr(rawdata, connection.msgtype)\n",
    "            video.write(bridge.imgmsg_to_cv2(msg, desired_encoding=\"bgr8\"))\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db3_connection = sqlite3.connect(db3_path)\n",
    "cursor = db3_connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['std_msgs/Header', 'uint32', 'uint32', 'string', 'uint8', 'uint32', 'uint8[]']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_message._get_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typestore = get_typestore(Stores.LATEST)\n",
    "with Writer(\"output_ros2_2\") as writer, Reader(INPUT_BAGFILE) as reader:\n",
    "    topic = '/chatter'\n",
    "    msgtype = String.__msgtype__\n",
    "    connection = writer.add_connection(topic, msgtype, typestore=typestore)\n",
    "\n",
    "    # Serialize and write message.\n",
    "    timestamp = 42\n",
    "    message = String('hello world')\n",
    "    writer.write(connection, timestamp, typestore.serialize_cdr(message, msgtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rosbags.typesys import Stores, get_typestore\n",
    "\n",
    "typestore = get_typestore(Stores.ROS2_FOXY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action_msgs/msg/GoalInfo': rosbags.typesys.stores.ros2_dashing.action_msgs__msg__GoalInfo,\n",
       " 'action_msgs/msg/GoalStatus': rosbags.typesys.stores.ros2_dashing.action_msgs__msg__GoalStatus,\n",
       " 'action_msgs/msg/GoalStatusArray': rosbags.typesys.stores.ros2_dashing.action_msgs__msg__GoalStatusArray,\n",
       " 'actionlib_msgs/msg/GoalID': rosbags.typesys.stores.ros2_dashing.actionlib_msgs__msg__GoalID,\n",
       " 'actionlib_msgs/msg/GoalStatus': rosbags.typesys.stores.ros2_dashing.actionlib_msgs__msg__GoalStatus,\n",
       " 'actionlib_msgs/msg/GoalStatusArray': rosbags.typesys.stores.ros2_dashing.actionlib_msgs__msg__GoalStatusArray,\n",
       " 'builtin_interfaces/msg/Duration': rosbags.typesys.stores.empty.builtin_interfaces__msg__Duration,\n",
       " 'builtin_interfaces/msg/Time': rosbags.typesys.stores.empty.builtin_interfaces__msg__Time,\n",
       " 'diagnostic_msgs/msg/DiagnosticArray': rosbags.typesys.stores.ros2_dashing.diagnostic_msgs__msg__DiagnosticArray,\n",
       " 'diagnostic_msgs/msg/DiagnosticStatus': rosbags.typesys.stores.ros2_dashing.diagnostic_msgs__msg__DiagnosticStatus,\n",
       " 'diagnostic_msgs/msg/KeyValue': rosbags.typesys.stores.ros2_dashing.diagnostic_msgs__msg__KeyValue,\n",
       " 'geometry_msgs/msg/Accel': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__Accel,\n",
       " 'geometry_msgs/msg/AccelStamped': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__AccelStamped,\n",
       " 'geometry_msgs/msg/AccelWithCovariance': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__AccelWithCovariance,\n",
       " 'geometry_msgs/msg/AccelWithCovarianceStamped': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__AccelWithCovarianceStamped,\n",
       " 'geometry_msgs/msg/Inertia': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__Inertia,\n",
       " 'geometry_msgs/msg/InertiaStamped': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__InertiaStamped,\n",
       " 'geometry_msgs/msg/Point': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__Point,\n",
       " 'geometry_msgs/msg/Point32': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__Point32,\n",
       " 'geometry_msgs/msg/PointStamped': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__PointStamped,\n",
       " 'geometry_msgs/msg/Polygon': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__Polygon,\n",
       " 'geometry_msgs/msg/PolygonStamped': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__PolygonStamped,\n",
       " 'geometry_msgs/msg/Pose': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__Pose,\n",
       " 'geometry_msgs/msg/Pose2D': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__Pose2D,\n",
       " 'geometry_msgs/msg/PoseArray': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__PoseArray,\n",
       " 'geometry_msgs/msg/PoseStamped': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__PoseStamped,\n",
       " 'geometry_msgs/msg/PoseWithCovariance': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__PoseWithCovariance,\n",
       " 'geometry_msgs/msg/PoseWithCovarianceStamped': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__PoseWithCovarianceStamped,\n",
       " 'geometry_msgs/msg/Quaternion': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__Quaternion,\n",
       " 'geometry_msgs/msg/QuaternionStamped': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__QuaternionStamped,\n",
       " 'geometry_msgs/msg/Transform': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__Transform,\n",
       " 'geometry_msgs/msg/TransformStamped': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__TransformStamped,\n",
       " 'geometry_msgs/msg/Twist': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__Twist,\n",
       " 'geometry_msgs/msg/TwistStamped': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__TwistStamped,\n",
       " 'geometry_msgs/msg/TwistWithCovariance': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__TwistWithCovariance,\n",
       " 'geometry_msgs/msg/TwistWithCovarianceStamped': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__TwistWithCovarianceStamped,\n",
       " 'geometry_msgs/msg/Vector3': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__Vector3,\n",
       " 'geometry_msgs/msg/Vector3Stamped': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__Vector3Stamped,\n",
       " 'geometry_msgs/msg/Wrench': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__Wrench,\n",
       " 'geometry_msgs/msg/WrenchStamped': rosbags.typesys.stores.ros2_dashing.geometry_msgs__msg__WrenchStamped,\n",
       " 'lifecycle_msgs/msg/State': rosbags.typesys.stores.ros2_dashing.lifecycle_msgs__msg__State,\n",
       " 'lifecycle_msgs/msg/Transition': rosbags.typesys.stores.ros2_dashing.lifecycle_msgs__msg__Transition,\n",
       " 'lifecycle_msgs/msg/TransitionDescription': rosbags.typesys.stores.ros2_dashing.lifecycle_msgs__msg__TransitionDescription,\n",
       " 'lifecycle_msgs/msg/TransitionEvent': rosbags.typesys.stores.ros2_dashing.lifecycle_msgs__msg__TransitionEvent,\n",
       " 'nav_msgs/msg/GridCells': rosbags.typesys.stores.ros2_dashing.nav_msgs__msg__GridCells,\n",
       " 'nav_msgs/msg/MapMetaData': rosbags.typesys.stores.ros2_dashing.nav_msgs__msg__MapMetaData,\n",
       " 'nav_msgs/msg/OccupancyGrid': rosbags.typesys.stores.ros2_dashing.nav_msgs__msg__OccupancyGrid,\n",
       " 'nav_msgs/msg/Odometry': rosbags.typesys.stores.ros2_dashing.nav_msgs__msg__Odometry,\n",
       " 'nav_msgs/msg/Path': rosbags.typesys.stores.ros2_dashing.nav_msgs__msg__Path,\n",
       " 'rcl_interfaces/msg/FloatingPointRange': rosbags.typesys.stores.ros2_dashing.rcl_interfaces__msg__FloatingPointRange,\n",
       " 'rcl_interfaces/msg/IntegerRange': rosbags.typesys.stores.ros2_dashing.rcl_interfaces__msg__IntegerRange,\n",
       " 'rcl_interfaces/msg/ListParametersResult': rosbags.typesys.stores.ros2_dashing.rcl_interfaces__msg__ListParametersResult,\n",
       " 'rcl_interfaces/msg/Log': rosbags.typesys.stores.ros2_dashing.rcl_interfaces__msg__Log,\n",
       " 'rcl_interfaces/msg/Parameter': rosbags.typesys.stores.ros2_dashing.rcl_interfaces__msg__Parameter,\n",
       " 'rcl_interfaces/msg/ParameterDescriptor': rosbags.typesys.stores.ros2_dashing.rcl_interfaces__msg__ParameterDescriptor,\n",
       " 'rcl_interfaces/msg/ParameterEvent': rosbags.typesys.stores.ros2_dashing.rcl_interfaces__msg__ParameterEvent,\n",
       " 'rcl_interfaces/msg/ParameterEventDescriptors': rosbags.typesys.stores.ros2_dashing.rcl_interfaces__msg__ParameterEventDescriptors,\n",
       " 'rcl_interfaces/msg/ParameterType': rosbags.typesys.stores.ros2_dashing.rcl_interfaces__msg__ParameterType,\n",
       " 'rcl_interfaces/msg/ParameterValue': rosbags.typesys.stores.ros2_dashing.rcl_interfaces__msg__ParameterValue,\n",
       " 'rcl_interfaces/msg/SetParametersResult': rosbags.typesys.stores.ros2_dashing.rcl_interfaces__msg__SetParametersResult,\n",
       " 'rosgraph_msgs/msg/Clock': rosbags.typesys.stores.ros2_dashing.rosgraph_msgs__msg__Clock,\n",
       " 'sensor_msgs/msg/BatteryState': rosbags.typesys.stores.ros2_dashing.sensor_msgs__msg__BatteryState,\n",
       " 'sensor_msgs/msg/CameraInfo': rosbags.typesys.stores.ros2_dashing.sensor_msgs__msg__CameraInfo,\n",
       " 'sensor_msgs/msg/ChannelFloat32': rosbags.typesys.stores.ros2_dashing.sensor_msgs__msg__ChannelFloat32,\n",
       " 'sensor_msgs/msg/CompressedImage': rosbags.typesys.stores.ros2_dashing.sensor_msgs__msg__CompressedImage,\n",
       " 'sensor_msgs/msg/FluidPressure': rosbags.typesys.stores.ros2_dashing.sensor_msgs__msg__FluidPressure,\n",
       " 'sensor_msgs/msg/Illuminance': rosbags.typesys.stores.ros2_dashing.sensor_msgs__msg__Illuminance,\n",
       " 'sensor_msgs/msg/Image': rosbags.typesys.stores.ros2_dashing.sensor_msgs__msg__Image,\n",
       " 'sensor_msgs/msg/Imu': rosbags.typesys.stores.ros2_dashing.sensor_msgs__msg__Imu,\n",
       " 'sensor_msgs/msg/JointState': rosbags.typesys.stores.ros2_dashing.sensor_msgs__msg__JointState,\n",
       " 'sensor_msgs/msg/Joy': rosbags.typesys.stores.ros2_dashing.sensor_msgs__msg__Joy,\n",
       " 'sensor_msgs/msg/JoyFeedback': rosbags.typesys.stores.ros2_dashing.sensor_msgs__msg__JoyFeedback,\n",
       " 'sensor_msgs/msg/JoyFeedbackArray': rosbags.typesys.stores.ros2_dashing.sensor_msgs__msg__JoyFeedbackArray,\n",
       " 'sensor_msgs/msg/LaserEcho': rosbags.typesys.stores.ros2_dashing.sensor_msgs__msg__LaserEcho,\n",
       " 'sensor_msgs/msg/LaserScan': rosbags.typesys.stores.ros2_dashing.sensor_msgs__msg__LaserScan,\n",
       " 'sensor_msgs/msg/MagneticField': rosbags.typesys.stores.ros2_dashing.sensor_msgs__msg__MagneticField,\n",
       " 'sensor_msgs/msg/MultiDOFJointState': rosbags.typesys.stores.ros2_dashing.sensor_msgs__msg__MultiDOFJointState,\n",
       " 'sensor_msgs/msg/MultiEchoLaserScan': rosbags.typesys.stores.ros2_dashing.sensor_msgs__msg__MultiEchoLaserScan,\n",
       " 'sensor_msgs/msg/NavSatFix': rosbags.typesys.stores.ros2_dashing.sensor_msgs__msg__NavSatFix,\n",
       " 'sensor_msgs/msg/NavSatStatus': rosbags.typesys.stores.ros2_dashing.sensor_msgs__msg__NavSatStatus,\n",
       " 'sensor_msgs/msg/PointCloud': rosbags.typesys.stores.ros2_dashing.sensor_msgs__msg__PointCloud,\n",
       " 'sensor_msgs/msg/PointCloud2': rosbags.typesys.stores.ros2_dashing.sensor_msgs__msg__PointCloud2,\n",
       " 'sensor_msgs/msg/PointField': rosbags.typesys.stores.ros2_dashing.sensor_msgs__msg__PointField,\n",
       " 'sensor_msgs/msg/Range': rosbags.typesys.stores.ros2_dashing.sensor_msgs__msg__Range,\n",
       " 'sensor_msgs/msg/RegionOfInterest': rosbags.typesys.stores.ros2_dashing.sensor_msgs__msg__RegionOfInterest,\n",
       " 'sensor_msgs/msg/RelativeHumidity': rosbags.typesys.stores.ros2_dashing.sensor_msgs__msg__RelativeHumidity,\n",
       " 'sensor_msgs/msg/Temperature': rosbags.typesys.stores.ros2_dashing.sensor_msgs__msg__Temperature,\n",
       " 'sensor_msgs/msg/TimeReference': rosbags.typesys.stores.ros2_dashing.sensor_msgs__msg__TimeReference,\n",
       " 'shape_msgs/msg/Mesh': rosbags.typesys.stores.ros2_dashing.shape_msgs__msg__Mesh,\n",
       " 'shape_msgs/msg/MeshTriangle': rosbags.typesys.stores.ros2_dashing.shape_msgs__msg__MeshTriangle,\n",
       " 'shape_msgs/msg/Plane': rosbags.typesys.stores.ros2_dashing.shape_msgs__msg__Plane,\n",
       " 'shape_msgs/msg/SolidPrimitive': rosbags.typesys.stores.ros2_dashing.shape_msgs__msg__SolidPrimitive,\n",
       " 'std_msgs/msg/Bool': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__Bool,\n",
       " 'std_msgs/msg/Byte': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__Byte,\n",
       " 'std_msgs/msg/ByteMultiArray': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__ByteMultiArray,\n",
       " 'std_msgs/msg/Char': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__Char,\n",
       " 'std_msgs/msg/ColorRGBA': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__ColorRGBA,\n",
       " 'std_msgs/msg/Empty': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__Empty,\n",
       " 'std_msgs/msg/Float32': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__Float32,\n",
       " 'std_msgs/msg/Float32MultiArray': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__Float32MultiArray,\n",
       " 'std_msgs/msg/Float64': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__Float64,\n",
       " 'std_msgs/msg/Float64MultiArray': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__Float64MultiArray,\n",
       " 'std_msgs/msg/Header': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__Header,\n",
       " 'std_msgs/msg/Int16': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__Int16,\n",
       " 'std_msgs/msg/Int16MultiArray': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__Int16MultiArray,\n",
       " 'std_msgs/msg/Int32': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__Int32,\n",
       " 'std_msgs/msg/Int32MultiArray': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__Int32MultiArray,\n",
       " 'std_msgs/msg/Int64': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__Int64,\n",
       " 'std_msgs/msg/Int64MultiArray': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__Int64MultiArray,\n",
       " 'std_msgs/msg/Int8': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__Int8,\n",
       " 'std_msgs/msg/Int8MultiArray': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__Int8MultiArray,\n",
       " 'std_msgs/msg/MultiArrayDimension': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__MultiArrayDimension,\n",
       " 'std_msgs/msg/MultiArrayLayout': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__MultiArrayLayout,\n",
       " 'std_msgs/msg/String': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__String,\n",
       " 'std_msgs/msg/UInt16': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__UInt16,\n",
       " 'std_msgs/msg/UInt16MultiArray': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__UInt16MultiArray,\n",
       " 'std_msgs/msg/UInt32': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__UInt32,\n",
       " 'std_msgs/msg/UInt32MultiArray': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__UInt32MultiArray,\n",
       " 'std_msgs/msg/UInt64': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__UInt64,\n",
       " 'std_msgs/msg/UInt64MultiArray': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__UInt64MultiArray,\n",
       " 'std_msgs/msg/UInt8': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__UInt8,\n",
       " 'std_msgs/msg/UInt8MultiArray': rosbags.typesys.stores.ros2_dashing.std_msgs__msg__UInt8MultiArray,\n",
       " 'stereo_msgs/msg/DisparityImage': rosbags.typesys.stores.ros2_dashing.stereo_msgs__msg__DisparityImage,\n",
       " 'tf2_msgs/msg/TF2Error': rosbags.typesys.stores.ros2_dashing.tf2_msgs__msg__TF2Error,\n",
       " 'tf2_msgs/msg/TFMessage': rosbags.typesys.stores.ros2_dashing.tf2_msgs__msg__TFMessage,\n",
       " 'trajectory_msgs/msg/JointTrajectory': rosbags.typesys.stores.ros2_dashing.trajectory_msgs__msg__JointTrajectory,\n",
       " 'trajectory_msgs/msg/JointTrajectoryPoint': rosbags.typesys.stores.ros2_dashing.trajectory_msgs__msg__JointTrajectoryPoint,\n",
       " 'trajectory_msgs/msg/MultiDOFJointTrajectory': rosbags.typesys.stores.ros2_dashing.trajectory_msgs__msg__MultiDOFJointTrajectory,\n",
       " 'trajectory_msgs/msg/MultiDOFJointTrajectoryPoint': rosbags.typesys.stores.ros2_dashing.trajectory_msgs__msg__MultiDOFJointTrajectoryPoint,\n",
       " 'unique_identifier_msgs/msg/UUID': rosbags.typesys.stores.ros2_dashing.unique_identifier_msgs__msg__UUID,\n",
       " 'visualization_msgs/msg/InteractiveMarker': rosbags.typesys.stores.ros2_dashing.visualization_msgs__msg__InteractiveMarker,\n",
       " 'visualization_msgs/msg/InteractiveMarkerControl': rosbags.typesys.stores.ros2_dashing.visualization_msgs__msg__InteractiveMarkerControl,\n",
       " 'visualization_msgs/msg/InteractiveMarkerFeedback': rosbags.typesys.stores.ros2_dashing.visualization_msgs__msg__InteractiveMarkerFeedback,\n",
       " 'visualization_msgs/msg/InteractiveMarkerInit': rosbags.typesys.stores.ros2_dashing.visualization_msgs__msg__InteractiveMarkerInit,\n",
       " 'visualization_msgs/msg/InteractiveMarkerPose': rosbags.typesys.stores.ros2_dashing.visualization_msgs__msg__InteractiveMarkerPose,\n",
       " 'visualization_msgs/msg/InteractiveMarkerUpdate': rosbags.typesys.stores.ros2_dashing.visualization_msgs__msg__InteractiveMarkerUpdate,\n",
       " 'visualization_msgs/msg/MarkerArray': rosbags.typesys.stores.ros2_dashing.visualization_msgs__msg__MarkerArray,\n",
       " 'visualization_msgs/msg/MenuEntry': rosbags.typesys.stores.ros2_dashing.visualization_msgs__msg__MenuEntry,\n",
       " 'libstatistics_collector/msg/DummyMessage': rosbags.typesys.stores.ros2_foxy.libstatistics_collector__msg__DummyMessage,\n",
       " 'rmw_dds_common/msg/Gid': rosbags.typesys.stores.ros2_foxy.rmw_dds_common__msg__Gid,\n",
       " 'rmw_dds_common/msg/NodeEntitiesInfo': rosbags.typesys.stores.ros2_foxy.rmw_dds_common__msg__NodeEntitiesInfo,\n",
       " 'rmw_dds_common/msg/ParticipantEntitiesInfo': rosbags.typesys.stores.ros2_foxy.rmw_dds_common__msg__ParticipantEntitiesInfo,\n",
       " 'statistics_msgs/msg/MetricsMessage': rosbags.typesys.stores.ros2_foxy.statistics_msgs__msg__MetricsMessage,\n",
       " 'statistics_msgs/msg/StatisticDataPoint': rosbags.typesys.stores.ros2_foxy.statistics_msgs__msg__StatisticDataPoint,\n",
       " 'statistics_msgs/msg/StatisticDataType': rosbags.typesys.stores.ros2_foxy.statistics_msgs__msg__StatisticDataType,\n",
       " 'visualization_msgs/msg/ImageMarker': rosbags.typesys.stores.ros2_foxy.visualization_msgs__msg__ImageMarker,\n",
       " 'visualization_msgs/msg/Marker': rosbags.typesys.stores.ros2_foxy.visualization_msgs__msg__Marker}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typestore.types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
